# ETL Python - DummyJSON API ğŸš€

Este repositÃ³rio contÃ©m um pipeline de **ETL (Extract, Transform, Load)** desenvolvido para demonstrar o fluxo de consumo, armazenamento e transformaÃ§Ã£o de dados utilizando Python.

---

## ğŸ“ DescriÃ§Ã£o do Projeto

O objetivo deste projeto Ã© extrair dados semiestruturados de uma API pÃºblica ([DummyJSON](https://dummyjson.com/)), persistir esses dados em uma camada de "Raw" (dados brutos) e, posteriormente, transformÃ¡-los em arquivos estruturados (CSV) em uma camada "Curated".

## ğŸ—ï¸ Estrutura do RepositÃ³rio

Seguindo as melhores prÃ¡ticas de Engenharia de Dados, o projeto estÃ¡ organizado em camadas:

* **`raw/`**: Atua como uma *Landing Zone*. Aqui, os dados sÃ£o salvos em formato `.json` exatamente como vÃªm da API, garantindo a linhagem dos dados brutos.
    * `/user`: Arquivos JSON de usuÃ¡rios.
    * `/products`: Arquivos JSON de produtos.
* **`curated/`**: Camada de dados prontos para negÃ³cio. Os dados sÃ£o convertidos para `.csv` para facilitar o consumo por ferramentas de BI ou anÃ¡lise.
* **`main.py`**: O motor do projeto, contendo as funÃ§Ãµes de requisiÃ§Ã£o, paginaÃ§Ã£o e transformaÃ§Ã£o com Pandas.

## ğŸ› ï¸ Tecnologias Utilizadas

* **Python 3.x**: Linguagem base.
* **Requests**: Para comunicaÃ§Ã£o com a API REST.
* **Pandas & Numpy**: Para manipulaÃ§Ã£o de DataFrames e conversÃ£o de formatos.
* **JSON**: Para persistÃªncia e leitura de arquivos semiestruturados.

## ğŸš€ Como Funciona

1.  **ExtraÃ§Ã£o**: A funÃ§Ã£o `extracao_dados` realiza o consumo do endpoint especÃ­fico.
2.  **Carga (Raw)**: O script percorre os IDs (limite de 10 por padrÃ£o) e salva cada registro como um arquivo individual na pasta `raw/`.
3.  **TransformaÃ§Ã£o**: A funÃ§Ã£o `transform_data_json_to_csv` lÃª o arquivo JSON, carrega-o em um DataFrame do Pandas e o exporta para a pasta `curated/` com a extensÃ£o CSV.
